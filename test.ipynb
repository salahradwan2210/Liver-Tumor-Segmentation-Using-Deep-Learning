{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nibabel\n",
    "#!pip install imageio\n",
    "#!pip install ipywidgets\n",
    "#!pip install fastai\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import imageio\n",
    "from tqdm.notebook import tqdm\n",
    "from ipywidgets import *\n",
    "from PIL import Image\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment(seqA='ACGT', seqB='ACGT', score=4.0, start=0, end=4)\n"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "alignments = pairwise2.align.localxx(\"ACGT\", \"ACGT\")\n",
    "for a in alignments:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "alignments = pairwise2.align.globalmx(\"ACGCTGCAGCT\", \"ACGT\", 2, -1)\n",
    "print(len(alignments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dna =\"GATCCCCCGATATTATTTGC\"\n",
    "dna.find('TA') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a CountVectorizer for k-mers\u001b[39;00m\n\u001b[0;32m     11\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(analyzer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(k, k))\n\u001b[1;32m---> 12\u001b[0m kmers_vectorized \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkmers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Convert to array for visualization\u001b[39;00m\n\u001b[0;32m     15\u001b[0m kmers_array \u001b[38;5;241m=\u001b[39m kmers_vectorized\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:1294\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1296\u001b[0m         )\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Given DNA sequence\n",
    "sequence = \"GGAATGATCAAAGTAGTTTATG\"\n",
    "\n",
    "# Generate 3-mers\n",
    "k = 3\n",
    "kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "\n",
    "# Create a CountVectorizer for k-mers\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(k, k))\n",
    "kmers_vectorized = vectorizer.fit_transform(kmers)\n",
    "\n",
    "# Convert to array for visualization\n",
    "kmers_array = kmers_vectorized.toarray()\n",
    "\n",
    "print(kmers)\n",
    "print(kmers_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=[\"ATC\" , \"CGTGC\"]\n",
    "seq_2=\"_\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATC_CGTGC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCGUCGUA\n"
     ]
    }
   ],
   "source": [
    "def dna_to_rna(dna_sequence):\n",
    "    return dna_sequence.replace('T', 'U')\n",
    "\n",
    "# Example usage\n",
    "dna_sequence = \"ATCGTCGTA\"\n",
    "rna_sequence = dna_to_rna(dna_sequence)\n",
    "print(rna_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Salah_Radwan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Dummy data loading function\n",
    "def load_data():\n",
    "    # Replace these with actual loading code\n",
    "    x_valid = np.random.rand(10, 256, 256, 3)  # Example shape\n",
    "    y_valid = np.random.rand(10, 256, 256, 1)  # Example shape\n",
    "    return x_valid, y_valid\n",
    "\n",
    "x_valid, y_valid = load_data()\n",
    "\n",
    "@app.route('/visualize/<int:image_index>')\n",
    "def visualize(image_index):\n",
    "    input_image = x_valid[image_index]\n",
    "    true_mask = y_valid[image_index]\n",
    "\n",
    "    # Load your model\n",
    "    model2 = keras.models.load_model('modified_unet_model (2).h5')\n",
    "    predicted_mask = model2.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "    threshold = 0.5\n",
    "    predicted_mask_binary = (predicted_mask > threshold).astype(np.uint8)\n",
    "\n",
    "    # Create plots\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axs[0].imshow(input_image)\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[1].imshow(true_mask[:, :, 0], cmap='gray')\n",
    "    axs[1].set_title('True Mask')\n",
    "    axs[2].imshow(predicted_mask_binary[:, :, 0], cmap='gray')\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    axs[3].imshow(input_image, cmap='bone')\n",
    "    axs[3].imshow(predicted_mask_binary[:, :, 0], alpha=0.5, cmap='nipy_spectral')\n",
    "    axs[3].set_title('Overlay')\n",
    "\n",
    "    # Convert plot to PNG image\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "    plt.close()\n",
    "\n",
    "    return f'<img src=\"data:image/png;base64,{image_base64}\" />'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
